{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecção de Mudança"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definições Globais\n",
    "\n",
    "- **IS_LOCAL**: **True** - rodando programa localmente - sem acesso a GPU. **False** - rodando no Google Colab com acesso a GPU;\n",
    "- **IS_COLAB**: **True** - utiliza o Google Colab\n",
    "\n",
    "Alterações são necessárias na estrutura do código ao utilizar o [Google Colab](https://colab.research.google.com/). O Dataset estará no Drive. \n",
    "\n",
    "- ATENÇÃO: **TODO**: aprender a salvar arquivos no Google Drive quando a aplicação estiver utilizando o Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DATASET_PATH:\n",
    "- IS_PROTOTYPE:\n",
    "- BATCH_SIZE: \n",
    "- PATCH_SIDE:\n",
    "- N_EPOCHS:\n",
    "- NORMALISE_IMGS:\n",
    "- TRAIN_STRIDE:\n",
    "- BAND_TYPE:\n",
    "- LOAD_TRAINED:\n",
    "- DATA_AUG:\n",
    "- IS_LOCAL: **True** - rodando programa localmente - sem acesso a GPU. **False** - rodando no Google Colab com acesso a GPU;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global definitions - Ok\n"
     ]
    }
   ],
   "source": [
    "# Global variables definition\n",
    "\n",
    "# IS_PROTOTYPE = False\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "PATCH_SIDE = 96\n",
    "# N_EPOCHS = 50\n",
    "N_EPOCHS = 5 # hard to use large number of epochs even in colab\n",
    "\n",
    "# NORMALISE_IMGS = True\n",
    "\n",
    "TRAIN_STRIDE = int(PATCH_SIDE/2) - 1 # 47\n",
    "\n",
    "# ??\n",
    "BAND_TYPE = 4 # 0-RGB | 1-RGBIr | 2-All bands s.t. resulution <= 20m | 3-All bands\n",
    "\n",
    "# LOAD_TRAINED = False\n",
    "\n",
    "DATA_AUGMENTATION = True\n",
    "\n",
    "FP_MODIFIER = 10 # tunning parameter, use 1 if unsure\n",
    "\n",
    "DATASET_LOCAL_PATH = '/home/virginia/Github/change-detection/onera-oscd/OSCD/'\n",
    "DATASET_COLAB_PATH = '/content/dataset/MyDrive/OSCD/'\n",
    "\n",
    "if IS_COLAB:\n",
    "    DATASET_PATH = DATASET_COLAB_PATH\n",
    "else:\n",
    "    DATASET_PATH = DATASET_LOCAL_PATH\n",
    "\n",
    "print(\"Global definitions - Ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Colab setup - Ok\n"
     ]
    }
   ],
   "source": [
    "# initial definitions/imports for Google Colab\n",
    "\n",
    "IS_LOCAL = True\n",
    "IS_COLAB = False\n",
    "\n",
    "if IS_COLAB:\n",
    "    print(\"Using Google Colab...\")\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/dataset')\n",
    "    \n",
    "print(\"Google Colab setup - Ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas\n",
    "\n",
    "### Pytorch\n",
    "\n",
    "[Pytorch](https://pytorch.org/docs/stable/index.html) é uma biblioteca otimizada de *tensors* para *Deep Learning* que utiliza GPUs (*Central Processing Unit*) e CPUs (*Graphics Processing Unit*) - [diferença entre CPUs e GPUs](https://canaltech.com.br/hardware/o-que-e-cpu-gpu-diferencas-154939/).\n",
    "\n",
    "[Pytorch](https://en.wikipedia.org/wiki/PyTorch) é uma biblioteca de *Machine Learning* baseada em *Torch*, é utilizada em aplicações de visão computacional e processamento de linguagem natural, primeiramente desenvolvida pelo *Facebook's AI Research lab (FAIR)*. Vários *softwares* que utilizam *Deep Learning* são desenvolvidos com base em *Pytorch*, como por exemplo Tesla Autopilot, Uber's Pyro, uggingFace's Transformers, yTorch Lightning, and Catalyst.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch imported - Ok\n"
     ]
    }
   ],
   "source": [
    "# Pytorch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision.transforms as tr # transforms, data augmentation\n",
    "#...\n",
    "print(\"Pytorch imported - Ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models imported - Ok\n"
     ]
    }
   ],
   "source": [
    "# Models\n",
    "import import_ipynb\n",
    "\n",
    "from unet import unet\n",
    "%run ../models/f-res-unet.ipynb # import F_res_UNet\n",
    "#from ../models/f-res-unet.ipynb import F_res_UNet\n",
    "#import models/f-res-unet.ipynb\n",
    "\n",
    "print(\"Models imported - Ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTE 2\n"
     ]
    }
   ],
   "source": [
    "%run test.ipynb import Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class ChangeDetectionDataset\n",
      "Dataset imported - Ok\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "\n",
    "# import functions from dataset/\n",
    "%run ../dataset/dataset-utl.ipynb\n",
    "\n",
    "print(\"Dataset imported - Ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Others imported - Ok\n"
     ]
    }
   ],
   "source": [
    "# Other\n",
    "\n",
    "import nbimporter # help imports between notebooks\n",
    "import os # operational system\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pandas import read_csv\n",
    "from math import floor, ceil, sqrt, exp\n",
    "import time\n",
    "from scipy.ndimage import zoom # zoom image\n",
    "from tqdm import tqdm as tqdm # \"progress\" (taqadum, تقدّم) - te quiero demasiado\n",
    "from skimage import io # skimage.io.imread(fname[, as_gray, plugin]) - Load an image from file\n",
    "# ...\n",
    "\n",
    "print(\"Others imported - Ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "Recentes avanços na aquisição e processamento de imagens digitais permitiram o uso eficiente e inovador de dados fornecidos por meio de bases de dados em aplicações de inteligência artificial e redes neurais (ML, DL). Entretanto, ainda existe uma deficiência na obtenção dessa base de dados, pois determinadas técnicas computacionais necessitam de um grande volume de dados para fornecer soluções confiáveis e com capacidade de generalizar diferentes entradas. É nesse contexto que se inserem as técnicas de *Data Augmentation* em imagens.\n",
    "\n",
    "Essa técnica tem como intuito gerar novos dados virtuais a partir de exemplos reais para prover mais volume de informações e dar suporte ao desenvolvimento de aplicações mais robustas.\n",
    "\n",
    "Uma das técnicas que podem ser utilizadas é são métodos de transformações geométricas, por exemplo: *flipping*, rotação, translação, *cropping* (corte), *zoom* (escala), *shear* (cisalhamento).\n",
    "\n",
    "(Data Agmentation)[https://sol.sbc.org.br/livros/index.php/sbc/catalog/download/48/217/455-1?inline=1]\n",
    "\n",
    "TO-DO:\n",
    "- analisar *overfitting*\n",
    "- analisar *oversampling*\n",
    "\n",
    "### Compositions of transforms\n",
    "\n",
    "```\n",
    "torchvision.transforms.Compose(transforms)\n",
    "```\n",
    "\n",
    "- **transforms** (list of ```Transform``` objects) – list of transforms to compose.\n",
    "\n",
    "Composes several transforms together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation - Ok\n"
     ]
    }
   ],
   "source": [
    "if DATA_AUGMENTATION:\n",
    "    data_aug_transform = tr.Compose([RandomFlip(), RandomRot()])\n",
    "else:\n",
    "    data_aug_transform = None\n",
    "\n",
    "print(\"Data augmentation - Ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset\n",
    "\n",
    "Prepare Dataset to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [01:13<00:00,  5.23s/it]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = ChangeDetectionDataset(DATASET_PATH, train=True, stride=TRAIN_STRIDE, transform=data_aug_transform)\n",
    "\n",
    "if IS_COLAB: # don't forget to activate GPU in Google Colab\n",
    "    weights = torch.FloatTensor(train_dataset.weights).cuda()\n",
    "else:\n",
    "    weights = torch.FloatTensor(train_dataset.weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weights)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9973cb7371b5c2be5f18a8b8225bf4e6ad54a34fb5872a1bc006d10d97ce0f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python38564bitbasecondab918388200e74c19bbf7a29e3542111d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
